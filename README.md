# WebSource Downloader


A full-stack application to scrape and download a website's front-end assets (HTML, CSS, JS, images, fonts) as a zip file.

## ğŸš€ Features

- ğŸŒ Accepts a valid website link (e.g. https://example.com)
- ğŸ“¦ Scrapes and downloads front-end code (HTML, CSS, JS, images, fonts)
- ğŸ§± Organizes assets into a clean project folder
- ğŸ—œï¸ Generates a downloadable `.zip` of the folder
- ğŸ¨ Aesthetic, modern, and responsive UI (with animations)
- âŒ Error handling for invalid URLs or blocked resources

---

## ğŸ–¥ï¸ Tech Stack

| Layer      | Tools Used                                           |
|------------|------------------------------------------------------|
| Frontend   | React.js / Next.js, TailwindCSS                      |
| Backend    | Python (FastAPI / Flask) or Node.js (Express)        |
| Scraping   | wget / requests + BeautifulSoup / puppeteer          |
| Zipping    | Python `zipfile` module or Node `archiver` library   |

---

## ğŸ“ Project Structure

```
WEB-SOURCE-DOWNLOADER/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # Main FastAPI/Flask server logic
â”‚   â”œâ”€â”€ scraper.py           # Web scraping logic (wget/requests/BS4)
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ temp_scrape.zip      # Temporary zip file for download (auto-generated)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ .next/               # Next.js build folder
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ScraperForm.js   # React component for URL input form
â”‚   â”œâ”€â”€ node_modules/        # Frontend dependencies
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ _app.js          # Global App Component
â”‚   â”‚   â””â”€â”€ index.js         # Main landing page with form
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ styles/
â”‚       â””â”€â”€ globals.css      # Tailwind global styles
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ postcss.config.js
â”‚   â””â”€â”€ tailwind.config.js
â”‚
â”œâ”€â”€ venv/                    # Python virtual environment
â””â”€â”€ Readme.md
```

## Setup Instructions

### Backend
1. Navigate to the `backend` directory:
   ```bash
   cd backend
   ```
2. (Optional) Create and activate a virtual environment:
   ```bash
   python -m venv venv
   venv\Scripts\activate  # On Windows
   source venv/bin/activate  # On Mac/Linux
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
4. Start the backend server:
   ```bash
   uvicorn main:app --reload
   ```

### Frontend
1. Navigate to the `frontend` directory:
   ```bash
   cd ../frontend
   ```
2. Install dependencies:
   ```bash
   npm install
   ```
3. Start the frontend development server:
   ```bash
   npm run dev
   ```

### Usage
- Open your browser and go to `http://localhost:3000`.
- Enter the URL of the website you want to scrape.
- Click "Scrape Website".
- After processing, a download link for the zip file will appear.

---


**Note:** This tool is for educational/demo purposes. Some websites may block scraping or have complex asset loading that may not be fully captured.

**Note:** This tool is for educational/demo purposes. Some websites may block scraping or have complex asset loading that may not be fully captured.
